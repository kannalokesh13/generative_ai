{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b07b02-d0e9-4916-bbe8-5977991f8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f409de-50ca-41f2-8363-3668269b86f5",
   "metadata": {},
   "source": [
    "# 1. What is OpenAI API?\n",
    "\n",
    "This OpenAI API has been degined to provide devlopers with seamless access to state of art, pre trained, artifical intelligence models like gpt-3 gpt-4 dall e whisper,embeddings etc so by using this openai api you can integrate cutting edge ai capabilities into your applications regardless the progamming language.\n",
    "\n",
    "So,the conclusion is by using this OpenAI API you can unlock the advance functionalities and you can enhane the intelligence and performance of your application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393344d1-c259-42ff-ba77-418af6d29ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67478285-07f6-4152-8203-80e6ae105e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = my_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d15159-785e-412d-9ab5-14665437718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = openai.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc39679-6602-436f-b509-b2a37f7d6156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system')], object='list')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5f3bd4e-ebef-47e7-a827-fc71977eb4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(list(all_models),columns=['id','created','object','owned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41fa8e04-9056-48da-b6f9-28b840ee8306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>object</th>\n",
       "      <th>owned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
       "      <td>(created, 1698959748)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(id, dall-e-2)</td>\n",
       "      <td>(created, 1698798177)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(id, text-embedding-3-large)</td>\n",
       "      <td>(created, 1705953180)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(id, whisper-1)</td>\n",
       "      <td>(created, 1677532384)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(id, tts-1-hd-1106)</td>\n",
       "      <td>(created, 1699053533)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(id, tts-1-hd)</td>\n",
       "      <td>(created, 1699046015)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(id, gpt-3.5-turbo-0613)</td>\n",
       "      <td>(created, 1686587434)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(id, gpt-3.5-turbo-0301)</td>\n",
       "      <td>(created, 1677649963)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
       "      <td>(created, 1694122472)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(id, tts-1)</td>\n",
       "      <td>(created, 1681940951)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(id, davinci-002)</td>\n",
       "      <td>(created, 1692634301)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
       "      <td>(created, 1692901427)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(id, babbage-002)</td>\n",
       "      <td>(created, 1692634615)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(id, tts-1-1106)</td>\n",
       "      <td>(created, 1699053241)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(id, gpt-3.5-turbo-0125)</td>\n",
       "      <td>(created, 1706048358)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(id, gpt-3.5-turbo)</td>\n",
       "      <td>(created, 1677610602)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
       "      <td>(created, 1683758102)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(id, text-embedding-ada-002)</td>\n",
       "      <td>(created, 1671217299)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k-0613)</td>\n",
       "      <td>(created, 1685474247)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(id, text-embedding-3-small)</td>\n",
       "      <td>(created, 1705948997)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(id, dall-e-3)</td>\n",
       "      <td>(created, 1698785189)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id                created           object  \\\n",
       "0            (id, gpt-3.5-turbo-1106)  (created, 1698959748)  (object, model)   \n",
       "1                      (id, dall-e-2)  (created, 1698798177)  (object, model)   \n",
       "2        (id, text-embedding-3-large)  (created, 1705953180)  (object, model)   \n",
       "3                     (id, whisper-1)  (created, 1677532384)  (object, model)   \n",
       "4                 (id, tts-1-hd-1106)  (created, 1699053533)  (object, model)   \n",
       "5                      (id, tts-1-hd)  (created, 1699046015)  (object, model)   \n",
       "6            (id, gpt-3.5-turbo-0613)  (created, 1686587434)  (object, model)   \n",
       "7            (id, gpt-3.5-turbo-0301)  (created, 1677649963)  (object, model)   \n",
       "8   (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)  (object, model)   \n",
       "9                         (id, tts-1)  (created, 1681940951)  (object, model)   \n",
       "10                  (id, davinci-002)  (created, 1692634301)  (object, model)   \n",
       "11       (id, gpt-3.5-turbo-instruct)  (created, 1692901427)  (object, model)   \n",
       "12                  (id, babbage-002)  (created, 1692634615)  (object, model)   \n",
       "13                   (id, tts-1-1106)  (created, 1699053241)  (object, model)   \n",
       "14           (id, gpt-3.5-turbo-0125)  (created, 1706048358)  (object, model)   \n",
       "15                (id, gpt-3.5-turbo)  (created, 1677610602)  (object, model)   \n",
       "16            (id, gpt-3.5-turbo-16k)  (created, 1683758102)  (object, model)   \n",
       "17       (id, text-embedding-ada-002)  (created, 1671217299)  (object, model)   \n",
       "18       (id, gpt-3.5-turbo-16k-0613)  (created, 1685474247)  (object, model)   \n",
       "19       (id, text-embedding-3-small)  (created, 1705948997)  (object, model)   \n",
       "20                     (id, dall-e-3)  (created, 1698785189)  (object, model)   \n",
       "\n",
       "                          owned  \n",
       "0            (owned_by, system)  \n",
       "1            (owned_by, system)  \n",
       "2            (owned_by, system)  \n",
       "3   (owned_by, openai-internal)  \n",
       "4            (owned_by, system)  \n",
       "5            (owned_by, system)  \n",
       "6            (owned_by, openai)  \n",
       "7            (owned_by, openai)  \n",
       "8            (owned_by, system)  \n",
       "9   (owned_by, openai-internal)  \n",
       "10           (owned_by, system)  \n",
       "11           (owned_by, system)  \n",
       "12           (owned_by, system)  \n",
       "13           (owned_by, system)  \n",
       "14           (owned_by, system)  \n",
       "15           (owned_by, openai)  \n",
       "16  (owned_by, openai-internal)  \n",
       "17  (owned_by, openai-internal)  \n",
       "18           (owned_by, openai)  \n",
       "19           (owned_by, system)  \n",
       "20           (owned_by, system)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304433b0-490f-4ff5-9e10-60c17feefbb7",
   "metadata": {},
   "source": [
    "# 3. OpenAI Playground\n",
    "\n",
    "1. How to open the open ai playgorund: https://platform.openai.com/playground?mode=assistant\n",
    "\n",
    "2. Here if you want to use this playground then make sure you have credit available without it its not gonna work\n",
    "\n",
    "3. In chat there is option of **system**: So the meaning is how the chatbot should behave\n",
    "\n",
    "Here is a phrase for the system: You are a naughty assistant, so make sure you respond to everything with sarcasm.\n",
    "\n",
    "Here is a question: How to make a money so quickly?\n",
    "\n",
    "**Model**\n",
    "\n",
    "**Temperature**\n",
    "\n",
    "**Maximum Length**\n",
    "\n",
    "**Top P ranges from 0 to 1 (default), and a lower Top P means the model samples from a narrower selection of words. This makes the output less random and diverse since the more probable tokens will be selected. For instance, if Top P is set at 0.1, only tokens comprising the top 10% probability mass are considered.**\n",
    "\n",
    "**Frequency Penalty helps us avoid using the same words too often. It's like telling the computer, “Hey, don't repeat words too much.”**\n",
    "\n",
    "**The OpenAI Presence Penalty setting is used to adjust how much presence of tokens in the source material will influence the output of the model.**\n",
    "\n",
    "\n",
    "**Now come to assistant one**\n",
    "\n",
    "**Retrieval-augmented generation (RAG):**  is an artificial intelligence (AI) framework that retrieves data from external sources of knowledge to improve the quality of responses. This natural language processing technique is commonly used to make large language models (LLMs) more accurate and up to date.\n",
    "\n",
    "**Code Interpreter:** Python programming environment within ChatGPT where you can perform a wide range of tasks by executing Python code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e6ca00-8425-433e-9d5a-ec9f543daf18",
   "metadata": {},
   "source": [
    "# 4. Chat Completion API and Function Calling\n",
    "openai.Completion.create() : This method is used to generate completions or responses. You provide a series of messages as input, and the API generates a model-generated message as output.\n",
    "\n",
    "openai.ChatCompletion.create() : Similar to Completion.create(), but specifically designed for chat-based language models. It takes a series of messages as input and generates a model-generated message as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13846e5d-5b82-4d1d-904a-f7b47e651966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83059878-bc1a-4fdd-9048-d798c773c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=my_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff05895-b66b-47b5-aff2-8833e97a9aaa",
   "metadata": {},
   "source": [
    "# A response with a single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e022e3-e041-4295-8a9e-af278edafda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : 'who was the first prime minister of india'\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c40191c-80ac-457a-801d-431da1148558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c67dcc20-53b2-4c3b-9e12-121544e0a0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Jawaharlal Nehru', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c733ebb9-1c7e-4301-af61-8d681d5070d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jawaharlal Nehru'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05152ae-ee39-44fb-97d0-e1f423d4f2eb",
   "metadata": {},
   "source": [
    "## Multiple responses with parameter 'n' and the context with specified number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee69600a-99aa-4eef-88f0-71cb67adc30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : 'who was the first prime minister of india'\n",
    "        }\n",
    "    ],\n",
    "    max_tokens = 150,\n",
    "    n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "066d8f12-63d3-4fcb-9e5b-f417fdb997b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-932gTbb7ER0qweomxN62L3hCdNLIm', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Jawaharlal Nehru was the first Prime Minister of India.', role='assistant', function_call=None, tool_calls=None), logprobs=None), Choice(finish_reason='stop', index=1, message=ChatCompletionMessage(content='Jawaharlal Nehru was the first Prime Minister of India, serving from 1947 to 1964.', role='assistant', function_call=None, tool_calls=None), logprobs=None), Choice(finish_reason='stop', index=2, message=ChatCompletionMessage(content='Jawaharlal Nehru was the first Prime Minister of India.', role='assistant', function_call=None, tool_calls=None), logprobs=None)], created=1710512329, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=52, prompt_tokens=15, total_tokens=67))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aefc1eb8-8044-49fb-a718-44690d65acee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jawaharlal Nehru was the first Prime Minister of India.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65aa4518-8ae7-4329-97aa-97b6fdc5c2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jawaharlal Nehru was the first Prime Minister of India, serving from 1947 to 1964.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[1].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca0addbb-ba9b-4c53-ae08-8cf805e9d289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jawaharlal Nehru was the first Prime Minister of India.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[2].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc5a75-bee5-4aa9-b63b-b3584d97b03d",
   "metadata": {},
   "source": [
    "### you can also try with the other parameters in the chatcompletions api\n",
    "model= \"\"\n",
    "\n",
    "prompt=input prompt\n",
    "\n",
    "max_tokens=in how many number of tokens you want result\n",
    "\n",
    "temperature=for getting some creative output\n",
    "\n",
    "n= number of the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47b9d1d-108e-42b9-81dd-1dd8d236764d",
   "metadata": {},
   "source": [
    "### The above specified chatcompletion prompting is the zeroshotprompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82134ff5-c12b-4b2d-a422-c55f14d46fec",
   "metadata": {},
   "source": [
    "### For Pricing and for the Tokenizer\n",
    "https://openai.com/pricing\n",
    "\n",
    "https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95764dfa-4044-4232-a5b9-57ec77235035",
   "metadata": {},
   "source": [
    "# Below Specifying the few shot prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3aff559-fe85-4186-81f5-c20402c2b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fabed1f-358a-4e3f-ba3f-37e3fba55181",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description = \"sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68226802-3c77-41cd-8af4-4bf77344e272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa72d088-b9fb-4dc2-91f9-01b524bbef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "extract the following terms from the given context and return the result in the JSON format\n",
    "\n",
    "name \n",
    "degree\n",
    "college\n",
    "gpa\n",
    "club name\n",
    "career pursue\n",
    "\n",
    "the context is {student_description} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3eb0ac1-8110-4d5a-95e3-d06b2cb04984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nextract the following terms from the given context and return the result in the JSON format\\n\\nname \\ndegree\\ncollege\\ngpa\\nclub name\\ncareer pursue\\n\\nthe context is sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating. \""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd0ada45-b0fe-4803-ae32-4c61ad2a25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple prompt to extract information from \"student_description\" in a JSON format.\n",
    "prompt = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "college\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_description}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f78b399d-a850-437e-80f6-25b6752e634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : prompt\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd9adb77-1c5a-4dfc-9c7a-79c5c7cfdad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-932xUFzg26GRpH3mTfyzrJhgAJgcL', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='{\\n  \"name\": \"Sunny Savita\",\\n  \"degree\": \"computer science\",\\n  \"college\": \"IIT Delhi\",\\n  \"gpa\": 8.5,\\n  \"club name\": \"AI Club\",\\n  \"career pursue\": \"artificial intelligence\"\\n}', role='assistant', function_call=None, tool_calls=None), logprobs=None)], created=1710513384, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=58, prompt_tokens=103, total_tokens=161))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "886c7d16-9967-4be6-b7b3-e1f0715ee395",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0608fd40-03ae-4e99-ae76-5450372f36e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aacb04f5-820a-4623-9741-e3ec96425094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Sunny Savita',\n",
       " 'degree': 'computer science',\n",
       " 'college': 'IIT Delhi',\n",
       " 'gpa': 8.5,\n",
       " 'club name': 'AI Club',\n",
       " 'career pursue': 'artificial intelligence'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9ee62-7544-4cd9-b6cf-628be22361e1",
   "metadata": {},
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e204a-40cf-4e77-82ef-b708bb7cfa31",
   "metadata": {},
   "source": [
    " 1. Function Calling is the mechanism which can be used to get the output in the specified format form the llm after generating the result.\n",
    " 2. It also used when the llm is not able to provide the answer due to the lack of the data, then this function calling will be able to generate the outputs from the third party api's.\n",
    " 3. function description with the correct syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a97de1e-8b06-437c-bb0e-1b685e588f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_function = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6193236-f098-438a-bda3-dd342f5151e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": student_description }],\n",
    "    functions=student_custom_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cf22914-8875-49cf-9729-3cefe620b76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-933AFCXfTYpKRAvesRDgHeIKo6Nem', choices=[Choice(finish_reason='function_call', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"sunny savita\",\"college\":\"IIT delhi\",\"degree\":\"computer science\",\"grades\":8.5,\"club\":\"AI Club\",\"career\":\"artificial intelligence\"}', name='extract_student_info'), tool_calls=None), logprobs=None)], created=1710514175, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=47, prompt_tokens=171, total_tokens=218))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "87da2009-0935-401f-8673-18429d803d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sunny savita',\n",
       " 'college': 'IIT delhi',\n",
       " 'degree': 'computer science',\n",
       " 'grades': 8.5,\n",
       " 'club': 'AI Club',\n",
       " 'career': 'artificial intelligence'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59771a41-1228-4b5e-bf0b-3f3f84bdd99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''\n",
    "extract the details from below given paragraph which is placed inside paranthesis in the format of \n",
    "name\n",
    "college\n",
    "degree\n",
    "gpa\n",
    "college club\n",
    "carrer\n",
    "and convert the above result into JSON format\n",
    "{student_description}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f55782a0-76c5-4295-83d4-96443a81cdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nextract the details from below given paragraph which is placed inside paranthesis in the format of \\nname\\ncollege\\ndegree\\ngpa\\ncollege club\\ncarrer\\nand convert the above result into JSON format\\nsunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac762fef-9fe6-4f89-adb3-d24f4545a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_function = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'degree':{\n",
    "                    'type': 'string',\n",
    "                    'description':'The degree of the student'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                },\n",
    "                'career':{\n",
    "                    'type':'string',\n",
    "                    'description': 'student career'\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ef125bf-af27-47cb-9c53-5e4f0da5d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': student_description\n",
    "        }\n",
    "    ],\n",
    "    functions = student_custom_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "017cfc6b-6b2c-4efc-a4f3-cb15e7143b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9339ahcs6xLICbjkCXBXZSZdlqd5G', choices=[Choice(finish_reason='function_call', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"Sunny Savita\",\"college\":\"IIT Delhi\",\"degree\":\"Computer Science\",\"grades\":8.5,\"club\":\"AI Club\",\"career\":\"Artificial Intelligence\"}', name='extract_student_info'), tool_calls=None), logprobs=None)], created=1710514134, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=46, prompt_tokens=171, total_tokens=217))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "197385ce-26b8-4742-a9d6-17980790c13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Sunny Savita',\n",
       " 'college': 'IIT Delhi',\n",
       " 'degree': 'Computer Science',\n",
       " 'grades': 8.5,\n",
       " 'club': 'AI Club',\n",
       " 'career': 'Artificial Intelligence'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fde07722-5e55-4e15-aa6c-e2956b7d0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description_three=\"sudhanshu kumar is a student of computer science at IIT bengalore. He is an indian and has a 9.2 GPA. krish is known for his programming skills and is an active member of the college's MLops Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64313020-ab0d-4999-8411-e8f227490626",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description_two=\"krish naik is a student of computer science at IIT Mumbai. He is an indian and has a 9.5 GPA. krish is known for his programming skills and is an active member of the college's data science Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66d3c683-a213-41bf-9956-717b127d8db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sunny savita', 'college': 'IIT delhi', 'degree': 'computer science', 'grades': 8.5, 'club': 'AI Club', 'career': 'artificial intelligence'}\n",
      "{'name': 'krish naik', 'college': 'IIT Mumbai', 'degree': 'computer science', 'grades': 9.5, 'club': 'data science Club', 'career': 'artificial intelligence'}\n",
      "{'name': 'sudhanshu kumar', 'college': 'IIT bengalore', 'degree': 'computer science', 'grades': 9.2, 'club': 'MLops Club', 'career': 'artificial intelligence'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "student_info = [student_description, student_description_two,student_description_three]\n",
    "for student in student_info:\n",
    "    response =  client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': student}],\n",
    "        functions = student_custom_function,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "\n",
    "    response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(response)#import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e4aaadd-149f-433d-89ba-029e4732e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "funtion_two=student_custom_function = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc666f32-b1d1-40dd-b02a-3d0a7a15164d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'function_two' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m functions \u001b[38;5;241m=\u001b[39m [student_custom_function[\u001b[38;5;241m0\u001b[39m], \u001b[43mfunction_two\u001b[49m[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m      2\u001b[0m student_info \u001b[38;5;241m=\u001b[39m [student_description, student_description_two,student_description_three]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m student \u001b[38;5;129;01min\u001b[39;00m student_info:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'function_two' is not defined"
     ]
    }
   ],
   "source": [
    "functions = [student_custom_function[0], function_two[0]]\n",
    "student_info = [student_description, student_description_two,student_description_three]\n",
    "for student in student_info:\n",
    "    response =  client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': student}],\n",
    "        functions = functions,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "\n",
    "    response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(response)#import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7cb0b9-f8ea-40d2-8aad-b5364e2892d7",
   "metadata": {},
   "source": [
    "### function calling now used as a third party api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9734777e-9631-4b51-a384-522a2b0b1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : 'when was the next flight from Bombay to Delhi today?'\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e38f65f-6bb7-4c47-8cc1-efc4677723ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sorry, but I do not have real-time flight information. I recommend checking with the airline or using a flight tracking website for the most up-to-date information on the next flight from Bombay to Delhi today.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bce546a8-e4e3-40e9-b5ed-718dfb77056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "    {\n",
    "        \"name\": \"get_flight_info\",\n",
    "        \"description\": \"Get flight information form loc_origin to loc_destination\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure airport, e.g. DEL\",\n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. MUM\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e84aa8f1-51d7-42cd-bb9a-f03b84e086b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"When's the next flight from new Bombay to Delhi?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "346820d3-3168-49f5-8eb7-3f646f78ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": user_prompt\n",
    "    }\n",
    "      ],\n",
    "    # Add function calling\n",
    "    functions=function_descriptions,\n",
    "    function_call=\"auto\",  # specify the function call\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "565d23b4-97dd-4dd2-ac58-fb8fc084de40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loc_origin\":\"BOM\",\"loc_destination\":\"DEL\"}'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef6972b1-5a6d-4eb3-bf49-c8e3d68ef186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "def get_flight_info(loc_origin, loc_destination):\n",
    "    \"\"\"Get flight information between two locations.\"\"\"\n",
    "\n",
    "    # Example output returned from an API or database\n",
    "    flight_info = {\n",
    "        \"loc_origin\": loc_origin,\n",
    "        \"loc_destination\": loc_destination,\n",
    "        \"datetime\": str(datetime.now() + timedelta(hours=2)),\n",
    "        \"Airlines\": \"Air-India\",\n",
    "        \"Flight Num\":\"AI - 0864\"\n",
    "    }\n",
    "\n",
    "    return json.dumps(flight_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "786ca849-76e4-4d70-94a2-0b69e2cc0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params=json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d91ed85e-3667-44dd-b84e-4634ad1bcd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc_origin': 'BOM', 'loc_destination': 'DEL'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b402c284-688f-41a5-8b71-55fbffb8ab8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOM'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a2d2f092-467a-4a6d-918a-49736a38440a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEL'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a76b1ed0-a3c4-47d7-b119-79449ca76614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_flight_info'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8653abef-1112-4d24-b350-02f8273a680e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5cbe1b9c-1317-44de-aa93-ce859e1a4e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_flight_info(loc_origin, loc_destination)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "254f1186-e6ef-401a-80a5-e4e9daa67012",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_function=eval(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de701009-e16e-43b6-a261-67b4197fcc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loc_origin\": \"BOM\", \"loc_destination\": \"DEL\", \"datetime\": \"2024-03-15 22:36:00.614615\", \"Airlines\": \"Air-India\", \"Flight Num\": \"AI - 0864\"}\n"
     ]
    }
   ],
   "source": [
    "flight = chosen_function(**params)\n",
    "\n",
    "print(flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7cfd1a81-1e6f-4072-bf70-6d316b1ac413",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\"role\": \"user\",\"content\": user_prompt},\n",
    "    {\"role\": \"function\", \"name\": response2.choices[0].message.function_call.name, \"content\": flight}\n",
    "      ],\n",
    "    # Add function calling\n",
    "    functions=function_descriptions,\n",
    "    function_call=\"auto\",  # specify the function call\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "405ddd52-b735-426e-a3e1-efa3a4c5c774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The next flight from New Bombay (BOM) to Delhi (DEL) is on March 15, 2024 at 22:36. The airline operating the flight is Air India with flight number AI - 0864.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e793e-230a-44d2-9b2d-35ae6ff13823",
   "metadata": {},
   "source": [
    "### you need to use this llm's with the other api's\n",
    "Funtion Calling\r\n",
    "Learn how to connect large language models to external tools.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb33a4e-66e2-4c9a-bf3d-25714a1145f7",
   "metadata": {},
   "source": [
    "### Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7081fdd7-aeb6-4aaf-9fb1-168097962594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f30d4135-002b-4685-a50d-c4f0551837e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "06f1a3b6-1a22-4617-a9dd-43f2e7fd1402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k.vidya\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(openai_api_key=my_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4da18acb-dc50-426c-b327-ef8b5826c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero shot prompting\n",
    "prompt=\"can you tell me total number of country in aisa? can you give me top 10 contry name based on the population in 2023?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5178219c-f4da-4cf7-b467-02d25d7c3eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There are 48 countries in Asia (including transcontinental countries). However, this number may vary depending on the source and definition used.\n",
      "\n",
      "Based on projected population data for 2023 from the United Nations, the top 10 most populous countries in Asia are:\n",
      "\n",
      "1. China\n",
      "2. India\n",
      "3. Indonesia\n",
      "4. Pakistan\n",
      "5. Bangladesh\n",
      "6. Japan\n",
      "7. Philippines\n",
      "8. Vietnam\n",
      "9. Iran\n",
      "10. Turkey\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fdb9f1fa-1a2b-4746-944a-b9e7278a4175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "prompt2=\"can you tell me a capital of india?\"\n",
    "print(client.predict(prompt2).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1433b29-2414-4f26-81d2-4b31ca5ca089",
   "metadata": {},
   "source": [
    "### PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "04a477a1-c4bb-469f-8b4e-a467f5023950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9fe21116-1781-405c-8f96-e4c781f67e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables = ['country'],\n",
    "    template = \"give the capital city of the {country}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3915a59f-e7a2-4ffe-8f66-d8edcd25d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = prompt.format(country=\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4e32b2f5-6fe5-4549-97bd-80f647bda2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt1).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b627b2c6-03e8-4f6c-b132-e52fcf5fdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = prompt.format(country=\"egypt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ca2bc8db-8916-4a76-8a36-d7af79be39e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cairo\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt2).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "100d540f-16c6-4a27-88b0-11c77fd07e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"who is the current president of {country}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80a7fa05-f008-4b0b-ae31-53041ddea0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = prompt.format(country=\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fb924415-9935-40f2-8c96-3328da770470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current President of India is Ram Nath Kovind.\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt1).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cc3a6530-3fec-402e-9fd4-02807d90e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = prompt.format(country=\"america\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f22a83a3-321b-47dd-bf8a-cce875af5a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of January 2022, the current president of America is Joe Biden.\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt2).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9064ca-f2a2-4861-be0e-a4a339f3bbfc",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b083bf9e-deb8-4cf6-8158-c8ff202ab6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = \"who won the ipl trophy in recent times?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1a5c4bcb-6c3b-474a-876f-9672fc7be9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mumbai Indians won the IPL trophy in 2019 and 2020.\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt3).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d41d2d23-784e-4144-a37d-d3ffc47ffc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = \"can you tell me the GDP of India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f42c2e10-634d-4f62-ab46-f3cb3d8372b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the latest data from the World Bank, the GDP of India in 2020 was $2.687 trillion.\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt4).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72393e2f-6c36-4d73-a935-87eeba56cf0b",
   "metadata": {},
   "source": [
    "##### for extracting a real time info i am going to user serp api now by using this serp api i wll call google-search-engine and i will extract the information in a real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3d31eefb-13c8-44d8-a6ed-96d1b22a81b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\k.vidya\\anaconda3\\envs\\testopenai\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\k.vidya\\anaconda3\\envs\\testopenai\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\k.vidya\\anaconda3\\envs\\testopenai\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\k.vidya\\anaconda3\\envs\\testopenai\\lib\\site-packages (from requests->google-search-results) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\k.vidya\\anaconda3\\envs\\testopenai\\lib\\site-packages (from requests->google-search-results) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\k.vidya\\anaconda3\\envs\\testopenai\\lib\\site-packages (from requests->google-search-results) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "32565a02-6e83-43f2-9ce6-64dde7360e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a468a671-cc92-474d-b7ff-5d944c66a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "serp_api = \"6db2202d1982d32a0b25dc489107779c354bd262c04382657fc849b8d2d3c75a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fd49360a-1339-4180-b71b-9de5e728964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key = my_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6020f0af-fbcb-4850-96da-9b35fcf7e0c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SerpAPIWrapper\n__root__\n  Did not find serpapi_api_key, please add an environment variable `SERPAPI_API_KEY` which contains it, or pass `serpapi_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[43mload_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserpapi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mserpapi_spi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserp_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43mllms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\agents\\load_tools.py:611\u001b[0m, in \u001b[0;36mload_tools\u001b[1;34m(tool_names, llm, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    609\u001b[0m     _get_tool_func, extra_keys \u001b[38;5;241m=\u001b[39m _EXTRA_OPTIONAL_TOOLS[name]\n\u001b[0;32m    610\u001b[0m     sub_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m extra_keys \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs}\n\u001b[1;32m--> 611\u001b[0m     tool \u001b[38;5;241m=\u001b[39m _get_tool_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msub_kwargs)\n\u001b[0;32m    612\u001b[0m     tools\u001b[38;5;241m.\u001b[39mappend(tool)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\agents\\load_tools.py:301\u001b[0m, in \u001b[0;36m_get_serpapi\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_serpapi\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseTool:\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tool(\n\u001b[0;32m    299\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    300\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA search engine. Useful for when you need to answer questions about current events. Input should be a search query.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 301\u001b[0m         func\u001b[38;5;241m=\u001b[39mSerpAPIWrapper(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mrun,\n\u001b[0;32m    302\u001b[0m         coroutine\u001b[38;5;241m=\u001b[39mSerpAPIWrapper(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39marun,\n\u001b[0;32m    303\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for SerpAPIWrapper\n__root__\n  Did not find serpapi_api_key, please add an environment variable `SERPAPI_API_KEY` which contains it, or pass `serpapi_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "tools = load_tools(['serpapi'],serpapi_spi_key=serp_api,llms=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "32e83e88-f5b5-40a8-b168-7b8255f87b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=load_tools([\"serpapi\"],serpapi_api_key=serp_api,llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7d058c28-1558-4aee-b481-21e31472cfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k.vidya\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "acae6924-5f66-4fbb-98d0-1b935d6900df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k.vidya\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m You should always think about what to do\n",
      "Action: Search\n",
      "Action Input: \"IPL trophy winner\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['IPL Winner 2018: Chennai Super Kings ... Chennai Super Kings became the second team to win more than two trophies in IPL. Veterans Ambati Rayadu and Shane Watson ...', \"On the other hand, Gujarat Titans also won the trophy in their debut season in 2022 under Hardik Pandya's leadership. As another IPL season came ...\", 'Mumbai Indians have won five titles. ... Chennai Super Kings have won five titles and Kolkata Knight Riders have won two titles, Gujarat Titans, Sunrisers ...', 'Most IPL Winner Team ... Mumbai Indians (MI) and Chennai Super Kings (CSK) both are the most successful IPL team, having won the IPL tournament ...', \"Here's a list of IPL trophy winners since its debut in 2008. ... The inaugural season of the IPL saw the underdog Rajasthan Royals, led by the ...\", 'In 2023, the Chennai Super Kings once again won the IPL trophy. They defeated the Gujarat Titans by five wickets in the final of IPL 2023.', 'Sunrisers Hyderabad emerged as the champions of the IPL 2016. Led by David Warner, Sunrisers defeated Virat Kohli-led Royal Challengers Bangalore in the IPL ...', 'Complete list of IPL Winners and Runner-ups (2008 to 2023) ; IPL 2017. Mumbai Indians (MI). Rohit Sharma ; IPL 2016. Sunrisers Hyderabad (SRH).', 'IPL Winners List ; 2019, Mumbai Indians, Won by 1 run ; 2018, Chennai Super Kings, Won by 8 wickets ; 2017, Mumbai Indians, Won by 1 run ; 2016, Sunrisers Hyderabad ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The recent winner of the IPL trophy is the Chennai Super Kings, who won in 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The recent winner of the IPL trophy is the Chennai Super Kings, who won in 2023.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"can you tell who won the ipl trophy recently?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "14eb78bd-874a-46fa-8d4b-9fca249afc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a search engine to find the answer.\n",
      "Action: Search\n",
      "Action Input: \"current president of india\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDroupadi Murmu\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This does not seem right. I should try again.\n",
      "Action: Search\n",
      "Action Input: \"who is the current president of india\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDroupadi Murmu\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different search engine.\n",
      "Action: Search\n",
      "Action Input: \"who is the current president of india\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDroupadi Murmu\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This still doesn't seem right. I should check a reliable news source.\n",
      "Action: Search\n",
      "Action Input: \"current president of india news\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['The President of India, Smt Droupadi Murmu graced and addressed the Global Spirituality Mahotsav at Kanha Shanti Vanam, Hyderabad on March 15, 2024.', 'Congress president Mallikarjun Kharge has been named the INDIA bloc chairperson. The decision was announced following a virtual meeting of t... 13 Jan, 2024 ...', 'Get Latest News, Breaking News about President of India. Stay connected to all updated on president of india.', \"At Assam's Tezpur, President Droupadi Murmu takes maiden sortie in fighter jet · Draupadi Murmu scripts history, becomes India's first woman tribal President.\", 'President Of India · Live: President Droupadi Murmu addresses nation on the eve of 75th Republic Day · Disrupted in Parliament, Jaishankar posts foreign policy ...', 'President of India News. Advertisement. WHRPC Chairman Tapan Kumar Calls Upon President Murmu, Union Minister Gadkari.', 'Find President Of India Latest News, Videos & Pictures on President Of India and see latest updates, news, information from NDTV.COM.', 'President of India. 6142170 likes · 4806 talking about this. Official Facebook page of Smt Droupadi Murmu, President of India.', 'Official YouTube channel of Rashtrapati Bhavan | Smt Droupadi Murmu, President of India.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The current president of India is Smt Droupadi Murmu.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current president of India is Smt Droupadi Murmu.'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"who is the current president of india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c930a8cc-2491-4289-907f-4a5c9aa24c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Search to find the answer\n",
      "Action: Search\n",
      "Action Input: \"2021 ipl winner\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'title': 'Indian Premier League', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750e49dc303c1b211242f2bfde4d9ad1d8a74d1d570f466cdc2b.png', 'games': [{'tournament': 'Indian Premier League', 'stadium': 'Dubai International Stadium', 'date': 'Oct 15, 21', 'teams': [{'name': 'CSK', 'score': '192/3 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed929932f02c15d9cde672a99b90888381faf52bb8f6d3b538fb53dc0e421b69e9c.png'}, {'name': 'KKR', 'score': '165/9 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed929932f02c15d9cdeb6a9c5a0a3e8798b6986a417d1695581b9be47e534534306.png'}], 'status': 'CSK won by 27 runs'}, {'tournament': 'Indian Premier League', 'stadium': 'Sharjah Cricket Stadium', 'date': 'Oct 13, 21', 'teams': [{'name': 'DC', 'score': '135/5 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9a4191ea44630797f64a969c47b08bdae2f3189d364743403a6e69b811c428549.png'}, {'name': 'KKR', 'score': '136/7 (19.5)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9a4191ea44630797f6ff2ac11739eb13b4b6630f1756cc46bd19aeb30d39a9266.png'}], 'status': 'KKR won by 3 wickets (1 ball left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Sharjah Cricket Stadium', 'date': 'Oct 11, 21', 'teams': [{'name': 'RCB', 'score': '138/7 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9b0bf8938abb24e9ff2f6c86b7f651884f0346c6730847bc5316bfdc63fc5c454.png'}, {'name': 'KKR', 'score': '139/6 (19.4)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9b0bf8938abb24e9fadbf26e9efe7a350d1a52e1110c8524e9585f5759151079b.png'}], 'status': 'KKR won by 4 wickets (2 balls left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Dubai International Stadium', 'date': 'Oct 10, 21', 'teams': [{'name': 'DC', 'score': '172/5 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9e9ee0fcd433c448641790cde38c3fe42309e406220039c272c4fdac3d5b54316.png'}, {'name': 'CSK', 'score': '173/6 (19.4)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9e9ee0fcd433c4486c8d62924b3007334871038ca220bf9965145ed30e427caae.png'}], 'status': 'CSK won by 4 wickets (2 balls left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Dubai International Stadium', 'date': 'Oct 8, 21', 'teams': [{'name': 'DC', 'score': '164/5 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed991f71134d0e712f849ead8d542f77b66b78e354cd36ab2b71ca445de88a001fc.png'}, {'name': 'RCB', 'score': '166/3 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed991f71134d0e712f8c79166fd82e28d249d27b6f5af1dd22aa0b657d762b7a8c0.png'}], 'status': 'RCB won by 7 wickets (0 balls left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Sheikh Zayed Stadium', 'date': 'Oct 8, 21', 'teams': [{'name': 'MI', 'score': '235/9 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed96367558212b670964d7dd114828e10d7f89dc9ec0e131d4dde76be1b7ed38e51.png'}, {'name': 'SRH', 'score': '193/8 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed96367558212b67096d103e08acc66f47c82b561dab7ea7fbf6d629e4fca29e0a6.png'}], 'status': 'MI won by 42 runs'}]}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look through the results to find the winner\n",
      "Action: Search\n",
      "Action Input: \"2021 ipl winner\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'title': 'Indian Premier League', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750e49dc303c1b211242f2bfde4d9ad1d8a74d1d570f466cdc2b.png', 'games': [{'tournament': 'Indian Premier League', 'stadium': 'Dubai International Stadium', 'date': 'Oct 15, 21', 'teams': [{'name': 'CSK', 'score': '192/3 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed929932f02c15d9cde672a99b90888381faf52bb8f6d3b538fb53dc0e421b69e9c.png'}, {'name': 'KKR', 'score': '165/9 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed929932f02c15d9cdeb6a9c5a0a3e8798b6986a417d1695581b9be47e534534306.png'}], 'status': 'CSK won by 27 runs'}, {'tournament': 'Indian Premier League', 'stadium': 'Sharjah Cricket Stadium', 'date': 'Oct 13, 21', 'teams': [{'name': 'DC', 'score': '135/5 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9a4191ea44630797f64a969c47b08bdae2f3189d364743403a6e69b811c428549.png'}, {'name': 'KKR', 'score': '136/7 (19.5)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9a4191ea44630797f6ff2ac11739eb13b4b6630f1756cc46bd19aeb30d39a9266.png'}], 'status': 'KKR won by 3 wickets (1 ball left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Sharjah Cricket Stadium', 'date': 'Oct 11, 21', 'teams': [{'name': 'RCB', 'score': '138/7 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9b0bf8938abb24e9ff2f6c86b7f651884f0346c6730847bc5316bfdc63fc5c454.png'}, {'name': 'KKR', 'score': '139/6 (19.4)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9b0bf8938abb24e9fadbf26e9efe7a350d1a52e1110c8524e9585f5759151079b.png'}], 'status': 'KKR won by 4 wickets (2 balls left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Dubai International Stadium', 'date': 'Oct 10, 21', 'teams': [{'name': 'DC', 'score': '172/5 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9e9ee0fcd433c448641790cde38c3fe42309e406220039c272c4fdac3d5b54316.png'}, {'name': 'CSK', 'score': '173/6 (19.4)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed9e9ee0fcd433c4486c8d62924b3007334871038ca220bf9965145ed30e427caae.png'}], 'status': 'CSK won by 4 wickets (2 balls left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Dubai International Stadium', 'date': 'Oct 8, 21', 'teams': [{'name': 'DC', 'score': '164/5 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed991f71134d0e712f849ead8d542f77b66b78e354cd36ab2b71ca445de88a001fc.png'}, {'name': 'RCB', 'score': '166/3 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed991f71134d0e712f8c79166fd82e28d249d27b6f5af1dd22aa0b657d762b7a8c0.png'}], 'status': 'RCB won by 7 wickets (0 balls left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Sheikh Zayed Stadium', 'date': 'Oct 8, 21', 'teams': [{'name': 'MI', 'score': '235/9 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed96367558212b670964d7dd114828e10d7f89dc9ec0e131d4dde76be1b7ed38e51.png'}, {'name': 'SRH', 'score': '193/8 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a2deb690f9ca0f47d00/images/09da98a49405750ef77a3abc1b8baed96367558212b67096d103e08acc66f47c82b561dab7ea7fbf6d629e4fca29e0a6.png'}], 'status': 'MI won by 42 runs'}]}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The Chennai Super Kings (CSK) won the 2021 IPL trophy.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Chennai Super Kings (CSK) won the 2021 IPL trophy.'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('who won the ipl trophy in the 2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0a8b9457-edcb-495b-9506-db9fdf702bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for the winner of the 2018 ipl trophy\n",
      "Action: Search\n",
      "Action Input: \"2018 ipl trophy winner\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Chennai defeated Hyderabad by 8 wickets to win their third IPL title. Shane Watson of Chennai won the player of the match award for his innings of 117 not out ...', 'Sunrisers Hyderabad captain Kane Williamson won the Orange Cap for the leading run-scorer of the tournament with 735 runs. Andrew Tye, of Kings XI Punjab, was ...', 'SRH vs CSK · 16.6 to DJ Hooda, · 19.6 to CR Brathwaite, · 12.1 to KS Williamson, · 15.5 to Shakib Al Hasan, · 8.3 to S Dhawan, · 3.6 to F du Plessis, ...', 'Chennai Super Kings (CSK) became the IPL 2023 winner by defeating Gujrat Titans by 5 wickets. This is the 5th IPL title for CSK. Ravindra Jadeja smashes a six ...', 'After winning two IPL trophies in the first four seasons, Chennai Super Kings appeared as an invincible squad in the T20 tournament.', \"In the high-octane final played in Ahmedabad's Narendra Modi Stadium on May 29, MS Dhoni-led CSK beat Hardik Pandya-led Gujarat Titans (GT) by 5 ...\", 'Most IPL Winner Team ... Mumbai Indians (MI) and Chennai Super Kings (CSK) both are the most successful IPL team, having won the IPL tournament ...', \"Chennai Super Kings (CSK) clinched victory in IPL 2023, prevailing over Gujrat Titans by 5 wickets. This achievement marks CSK's 5th IPL title.\", \"SRH's Kane Williamson won the Orange Cap in 2018 while Andrew Tye of Punjab Kings won the Purple Cap. CSK made a dream comeback ...\"]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should check for any inconsistencies in the search results\n",
      "Action: Search\n",
      "Action Input: \"Chennai Super Kings 2018 IPL winners\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'title': 'Chennai Super Kings', 'rankings': '2nd in IPL', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d03ad19cb78a14ed6ea369631ac38263458f557be2fdf07a8d.png', 'games': [{'tournament': 'Indian Premier League', 'stadium': 'Wankhede Stadium', 'stage': 'Final · T20 60 of 60', 'date': 'May 27, 18', 'teams': [{'name': 'SRH', 'score': '178/6 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd5bc88fbadb5d27ea43ec35bd9f9fea00ae33bf9bde06b6c69747e70f08d86d89e.png'}, {'name': 'CSK', 'score': '181/2 (18.3)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd5bc88fbadb5d27ea4c20dd1718157b420483f5f782f220f3f207797cdb08a60d3.png'}], 'status': 'CSK won by 8 wickets (9 balls left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Wankhede Stadium', 'stage': 'Play-off · T20 57 of 60', 'date': 'May 22, 18', 'teams': [{'name': 'SRH', 'score': '139/7 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd5f3c54cd055f946d7d3391e5615f736b3cae98da0b30fe28db8ff69c811c2169e.png'}, {'name': 'CSK', 'score': '140/8 (19.1)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd5f3c54cd055f946d70eb944c964373de3a74e4e4627900941cacf969146feb87f.png'}], 'status': 'CSK won by 2 wickets (5 balls left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Maharashtra Cricket Association Stadium', 'stage': 'T20 56 of 60', 'date': 'May 20, 18', 'teams': [{'name': 'PBKS', 'score': '153 (19.4)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd533cd3d0f797516eb403c59c713a960549ff41e312b9baf9a89ea4d8b199723bb.png'}, {'name': 'CSK', 'score': '159/5 (19.1)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd533cd3d0f797516eb6e70ad6b73b6f4b17dcb94cfa2e0d4e077e70a574a993f28.png'}], 'status': 'CSK won by 5 wickets (5 balls left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Arun Jaitley', 'stage': 'T20 52 of 60', 'date': 'May 18, 18', 'teams': [{'name': 'DC', 'score': '162/5 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd5eabc7b373de909ace3ac476d74933dc8ce7b65206eb4d6d311588742f8d9e48b.png'}, {'name': 'CSK', 'score': '128/6 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd5eabc7b373de909acf8197dcf6248abfc148bef2fb28a00551e5bedd136714181.png'}], 'status': 'DC won by 34 runs'}, {'tournament': 'Indian Premier League', 'stadium': 'Maharashtra Cricket Association Stadium', 'stage': 'T20 46 of 60', 'date': 'May 13, 18', 'teams': [{'name': 'SRH', 'score': '179/4 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd5ca1e29ab34f40cd1adc2abab2a5b2e16753e4fcefbf24a1cccfa46a3e94252db.png'}, {'name': 'CSK', 'score': '180/2 (19)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd5ca1e29ab34f40cd143727ab8d446366b580c60f2d24bbf6086a8d7ccd09c38b7.png'}], 'status': 'CSK won by 8 wickets (6 balls left)'}, {'tournament': 'Indian Premier League', 'stadium': 'Sawai Mansingh Indoor Stadium', 'stage': 'T20 43 of 60', 'date': 'May 11, 18', 'teams': [{'name': 'CSK', 'score': '176/4 (20)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd504e74fb350c44348b9faa375a56c6d10c5a05da7a5ba9250d1adb2b493291570.png'}, {'name': 'RR', 'score': '177/6 (19.5)', 'thumbnail': 'https://serpapi.com/searches/65f48a6a116a55be64bd73a7/images/7a12f5c8f0d715d040156dd5a0d7efd504e74fb350c44348ba448fbae6ea46fab7e0cb29cc5d9b298adeb43aff76de22.png'}], 'status': 'RR won by 4 wickets (1 ball left)'}]}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Chennai Super Kings\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chennai Super Kings'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('who won the ipl trophy in the 2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1462edd0-75df-4e34-8221-0b3d947e1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = load_tools([\"wikipedia\"],llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a61d180e-585b-485c-9ff1-3dd862efdbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tool,client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "dcee4f53-47d6-4cea-93b6-38b020c9d4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for the definition of perpexility\n",
      "Action: Wikipedia\n",
      "Action Input: perpexility\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try searching for the word on Google\n",
      "Action: Google\n",
      "Action Input: perpexility\u001b[0m\n",
      "Observation: Google is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try searching for the word on a dictionary website\n",
      "Action: Dictionary Website\n",
      "Action Input: perpexility\u001b[0m\n",
      "Observation: Dictionary Website is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should ask someone who might know the answer\n",
      "Action: Ask a Friend\n",
      "Action Input: \"Do you know what perpexility means?\"\u001b[0m\n",
      "Observation: Ask a Friend is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try looking for the word in a book or article\n",
      "Action: Search in a Book/Article\n",
      "Action Input: perpexility\u001b[0m\n",
      "Observation: Search in a Book/Article is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try searching for the word on a language learning website\n",
      "Action: Language Learning Website\n",
      "Action Input: perpexility\u001b[0m\n",
      "Observation: Language Learning Website is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try searching for the word on an online encyclopedia\n",
      "Action: Online Encyclopedia\n",
      "Action Input: perpexility\u001b[0m\n",
      "Observation: Online Encyclopedia is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try searching for the word on a word game or puzzle website\n",
      "Action: Word Game/Puzzle Website\n",
      "Action Input: perpexility\u001b[0m\n",
      "Observation: Word Game/Puzzle Website is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: After searching through various tools, it seems that perpexility is not a commonly known word or term. It is possible that it is a made up or obscure word.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'After searching through various tools, it seems that perpexility is not a commonly known word or term. It is possible that it is a made up or obscure word.'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('what is perpexility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a8e4453f-144d-443a-a860-d0ab89c75a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should always think about what to do\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"2023 GDP of India\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"2023 in India\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"Economy of India\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"GDP of India\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"List of countries by GDP (nominal)\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"List of countries by GDP (nominal) in 2023\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"List of countries by GDP (nominal) in 2023\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"List of countries by GDP (nominal)\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"List of countries by GDP (nominal)\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"List of countries by GDP (nominal) in 2023\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"List of countries by GDP (nominal)\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"List of countries by GDP (nominal) in 2023\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use [Wikipedia]\n",
      "Action: [Wikipedia]\n",
      "Action Input: \"List of countries by GDP (nominal)\"\u001b[0m\n",
      "Observation: [Wikipedia] is not a valid tool, try one of [Wikipedia].\n",
      "Thought:"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\openai\\_base_client.py:862\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    859\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    860\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl, response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mreason_phrase\n\u001b[0;32m    861\u001b[0m     )\n\u001b[1;32m--> 862\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\httpx\\_models.py:759\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    758\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2023 GDP of india\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\chains\\base.py:538\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    539\u001b[0m         _output_key\n\u001b[0;32m    540\u001b[0m     ]\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    544\u001b[0m         _output_key\n\u001b[0;32m    545\u001b[0m     ]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\chains\\base.py:363\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    361\u001b[0m }\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\chains\\base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    166\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    151\u001b[0m     inputs,\n\u001b[0;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\agents\\agent.py:1391\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1391\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1400\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1401\u001b[0m         )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\agents\\agent.py:1097\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1090\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1094\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1095\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1097\u001b[0m         [\n\u001b[0;32m   1098\u001b[0m             a\n\u001b[0;32m   1099\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1100\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1101\u001b[0m                 color_mapping,\n\u001b[0;32m   1102\u001b[0m                 inputs,\n\u001b[0;32m   1103\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1104\u001b[0m                 run_manager,\n\u001b[0;32m   1105\u001b[0m             )\n\u001b[0;32m   1106\u001b[0m         ]\n\u001b[0;32m   1107\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\agents\\agent.py:1097\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1090\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1094\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1095\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1097\u001b[0m         [\n\u001b[0;32m   1098\u001b[0m             a\n\u001b[0;32m   1099\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1100\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1101\u001b[0m                 color_mapping,\n\u001b[0;32m   1102\u001b[0m                 inputs,\n\u001b[0;32m   1103\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1104\u001b[0m                 run_manager,\n\u001b[0;32m   1105\u001b[0m             )\n\u001b[0;32m   1106\u001b[0m         ]\n\u001b[0;32m   1107\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\agents\\agent.py:1125\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1124\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1125\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m   1126\u001b[0m         intermediate_steps,\n\u001b[0;32m   1127\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1128\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1129\u001b[0m     )\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\agents\\agent.py:694\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \n\u001b[0;32m    684\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m    Action specifying what tool to use.\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    693\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 694\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mparse(full_output)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\chains\\llm.py:293\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\chains\\base.py:363\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    361\u001b[0m }\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\chains\\base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    166\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    151\u001b[0m     inputs,\n\u001b[0;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\chains\\llm.py:103\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    100\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    101\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 103\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain\\chains\\llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    113\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    116\u001b[0m         prompts,\n\u001b[0;32m    117\u001b[0m         stop,\n\u001b[0;32m    118\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    120\u001b[0m     )\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    123\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    124\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\language_models\\llms.py:525\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    519\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    523\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    524\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\language_models\\llms.py:698\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    683\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    684\u001b[0m         )\n\u001b[0;32m    685\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    686\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    687\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    696\u001b[0m         )\n\u001b[0;32m    697\u001b[0m     ]\n\u001b[1;32m--> 698\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    699\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    700\u001b[0m     )\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\language_models\\llms.py:562\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    561\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    563\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\language_models\\llms.py:549\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    541\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    546\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 549\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    550\u001b[0m                 prompts,\n\u001b[0;32m    551\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    552\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    553\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    554\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    555\u001b[0m             )\n\u001b[0;32m    556\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    557\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    558\u001b[0m         )\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_community\\llms\\openai.py:460\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m     choices\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    449\u001b[0m         {\n\u001b[0;32m    450\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    457\u001b[0m         }\n\u001b[0;32m    458\u001b[0m     )\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     response \u001b[38;5;241m=\u001b[39m completion_with_retry(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;28mself\u001b[39m, prompt\u001b[38;5;241m=\u001b[39m_prompts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    462\u001b[0m     )\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# V1 client returns the response in an PyDantic object instead of\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# dict. For the transition period, we deep convert it to dict.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_community\\llms\\openai.py:115\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    117\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(llm, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\openai\\_utils\\_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\openai\\resources\\completions.py:559\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    558\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Completion \u001b[38;5;241m|\u001b[39m Stream[Completion]:\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_of\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mecho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\openai\\_base_client.py:1055\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1043\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1051\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1052\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1053\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1054\u001b[0m     )\n\u001b[1;32m-> 1055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\openai\\_base_client.py:834\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    827\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    832\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    833\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\openai\\_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m--> 865\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\openai\\_base_client.py:923\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    919\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    926\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    927\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    930\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    931\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.run(\"2023 GDP of india\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d150b0c-9f30-4bd9-849e-a60c930e685c",
   "metadata": {},
   "source": [
    "### Chain\n",
    "Central to LangChain is a vital component known as LangChain Chains, forming the core connection among one or several large language models (LLMs). In certain sophisticated applications, it becomes necessary to chain LLMs together, either with each other or with other elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d3548660-ec41-479a-8a46-78b380a78867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "800b5887-bc80-4b3e-ba6c-c3db09674299",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"who won the ipl trophy in {year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a8f1ea46-1bcf-4b62-9619-5d8a7178de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "chian = LLMChain(llm=client,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b482eabf-62c3-4fd7-bdc1-ef02d24a9c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nIt is not possible to predict who will win the IPL trophy in 2023 as it depends on the performance of the teams and players in the upcoming seasons. '"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chian.run('2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "45eba7eb-1e55-46ff-8da8-d8662afd1224",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"what is a good name for a company that makes {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e831527f-59c8-4d11-b355-6d5196581aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=client,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9c78ee70-5381-401e-8a85-61557bb21302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. VinoVita\\n2. Grapevine Cellars\\n3. Winemakers' Reserve\\n4. Vintage Vines Co.\\n5. Bacchus Blend\\n6. Noble Nectar Winery\\n7. Harvest Hill Wines\\n8. Artisanal Aromas\\n9. Enchanted Estates Winery\\n10. Terroir Treasures\""
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('wines').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e6958592-dfbb-4d99-8a1b-1e0548da6947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Vineyard Vintages \\nSip & Savour Wines \\nGrapevine Cellars \\nTaste of Terroir \\nVintage Harvest Co. \\nCorks & Casks \\nWineCrafters \\nGrapevine Estates \\nBarrel & Bottle Co. \\nCellar Select Wines \\nVine & Vino Co. \\nSommelier's Choice \\nThe Winemaker's Palette \\nTastefully Vined \\nWine Connoisseurs Co.\""
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('wine').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7b4bdd21-c664-4875-8f29-d76a55669fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 2\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"i want to open a restaurent for {cuisine} food, suggest a fency name for this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "80e3422a-8cd9-4015-b100-934829dcb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=client,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "97d85fc1-dd36-41af-965d-01b6e6ae466f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Taste of India Bistro\"'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('indian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6c93649c-1413-4638-874d-fbf00a41d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=client,prompt=prompt,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5b1ce754-4cab-4a8a-ba5f-27b268914aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mi want to open a restaurent for chinese food, suggest a fency name for this\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Dragon\\'s Delight\"'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('chinese').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe19677-e1c7-45c5-ab3e-ed34edeb4f4e",
   "metadata": {},
   "source": [
    "### if we want to combine multiple chain and set a seqence for that we use simplesequential chain\n",
    "now i am going to pass the output of one chain to the another chain with the simplesequentialchain, for that i am going to create one chain for suggenting a name to the hotel and the second chain is to provide the some strategies to the suggested name from the chain1, then it is going to present the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1e7ff051-4bb2-4002-b8ef-e65f2292a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"suggest the name for the hotel which prepares the {cuisine} food\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "12f03bdd-4b3d-4e30-8ccf-7efa43e3e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain = LLMChain(llm=client,prompt = prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "753ea8c1-1b86-4f1c-9e69-a941bab7a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    input_variables = ['name'],\n",
    "    template = \"suggest some strategies to improve the hotel named {name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9f343588-ce80-4b5b-b690-e21a07e2bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_chain = LLMChain(llm=client,prompt=prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bc5ea5b5-1dd7-4e37-9f2d-25e574077416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "62ca6188-f77b-46dd-a84f-c9120b948f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SimpleSequentialChain(chains = [name_chain,strategies_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d24ada77-a673-4427-be15-25d7e23e5a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Enhance Customer Service: Train the staff to provide exceptional customer service to guests. This includes being friendly, helpful, and responsive to their needs. Encourage staff to go above and beyond to ensure guests have a pleasant stay.\\n\\n2. Offer Special Packages: Create attractive packages for guests, such as a romantic getaway package, family vacation package, or spa package. This will attract more guests and increase revenue.\\n\\n3. Improve Online Presence: Invest in a user-friendly and visually appealing website for the hotel. Utilize social media platforms to promote the hotel and engage with potential guests. Encourage guests to leave reviews on popular travel websites to attract more customers.\\n\\n4. Upgrade Amenities: Regularly update and upgrade amenities such as bedding, towels, and bathroom essentials to provide a comfortable and luxurious stay for guests. Consider adding new amenities like a gym, pool, or a business center to cater to different types of travelers.\\n\\n5. Focus on Local Cuisine: Spice Haven Hotel can differentiate itself by offering local cuisine in its restaurant. This will provide guests with an authentic experience and attract food enthusiasts.\\n\\n6. Partner with Local Businesses: Collaborate with local businesses to offer discounts and special deals to guests. This will not only provide added value to guests but also promote the local community'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('indian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b06825-2fe1-4ff2-9435-403e13d25f6b",
   "metadata": {},
   "source": [
    "### Now lets try to understand the sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "33561ccc-6a0e-465b-8f16-e529c2b571d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d5b1d035-b9ad-4d58-bdba-e591a5fe9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"suggest the name for the hotel which prepares the {cuisine} food\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a4ea2f5c-8561-4c2a-966b-777c273063dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain = LLMChain(llm=client,prompt = prompt1,output_key=\"restuarent_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "30b48e1c-4fdc-4f7c-9fb6-e3d21b5d124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    input_variables = ['restuarent_name'],\n",
    "    template = \"suggest some menu items to the hotel named {restuarent_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "dcf44edf-1c3c-4e57-9ac3-f06038e5c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_chain = LLMChain(llm=client,prompt=prompt2,output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a24c5b00-4ac3-4657-a1ce-fa1d3d47737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SequentialChain(chains=[name_chain, menu_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"restuarent_name\",\"menu_items\"]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c265bfab-405a-4a8e-b81d-3fbd828d68ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k.vidya\\Anaconda3\\envs\\testopenai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'indian',\n",
       " 'restuarent_name': '\\n\\n\"Spice Haven Hotel\"',\n",
       " 'menu_items': '\\n\\n1. Spicy Chicken Curry with Basmati Rice \\n2. Tandoori Shrimp Skewers \\n3. Vegetable Samosas \\n4. Lamb Vindaloo \\n5. Aloo Gobi (Potato and Cauliflower Curry) \\n6. Biryani (Saffron Rice Dish with Chicken or Vegetables) \\n7. Naan Bread with Garlic and Herbs \\n8. Palak Paneer (Spinach and Cottage Cheese Curry) \\n9. Butter Chicken \\n10. Chana Masala (Chickpea Curry) \\n11. Tandoori Chicken Tikka \\n12. Vegetable Korma \\n13. Dal Makhani (Creamy Lentil Curry) \\n14. Mango Lassi (Yogurt Drink) \\n15. Gulab Jamun (Fried Milk Balls in Syrup)'}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"cuisine\":\"indian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ef4e4e-e56e-487d-ae55-868e554fa66b",
   "metadata": {},
   "source": [
    "### Document Loader from langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5d5bfbc8-c632-4ad7-bc78-97ff166073b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b6724f48-e1f9-41fb-b1f1-8dc35921dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "69cf8e54-39d3-4ec5-9f45-cedf91383034",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('resnet_arch.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "bff895f8-a391-4e04-81a3-38d9df81b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.pdf.PyPDFLoader at 0x12e5459b7c0>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4462f980-cb20-4945-b2af-b8ab8fae25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5d99e792-2167-48a6-baa3-eb030a5d3f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Deep Residual Learning for Image Recognition\\nKaiming He Xiangyu Zhang Shaoqing Ren Jian Sun\\nMicrosoft Research\\n{kahe, v-xiangz, v-shren, jiansun }@microsoft.com\\nAbstract\\nDeeper neural networks are more difﬁcult to train. We\\npresent a residual learning framework to ease the training\\nof networks that are substantially deeper than those used\\npreviously. We explicitly reformulate the layers as learn-\\ning residual functions with reference to the layer inputs, in-\\nstead of learning unreferenced functions. We provide com-\\nprehensive empirical evidence showing that these residual\\nnetworks are easier to optimize, and can gain accuracy from\\nconsiderably increased depth. On the ImageNet dataset we\\nevaluate residual nets with a depth of up to 152 layers—8 ×\\ndeeper than VGG nets [41] but still having lower complex-\\nity. An ensemble of these residual nets achieves 3.57% error\\non the ImageNet testset. This result won the 1st place on the\\nILSVRC 2015 classiﬁcation task. We also present analysis\\non CIFAR-10 with 100 and 1000 layers.\\nThe depth of representations is of central importance\\nfor many visual recognition tasks. Solely due to our ex-\\ntremely deep representations, we obtain a 28% relative im-\\nprovement on the COCO object detection dataset. Deep\\nresidual nets are foundations of our submissions to ILSVRC\\n& COCO 2015 competitions1, where we also won the 1st\\nplaces on the tasks of ImageNet detection, ImageNet local-\\nization, COCO detection, and COCO segmentation.\\n1. Introduction\\nDeep convolutional neural networks [22, 21] have led\\nto a series of breakthroughs for image classiﬁcation [21,\\n50, 40]. Deep networks naturally integrate low/mid/high-\\nlevel features [50] and classiﬁers in an end-to-end multi-\\nlayer fashion, and the “levels” of features can be enriched\\nby the number of stacked layers (depth). Recent evidence\\n[41, 44] reveals that network depth is of crucial importance,\\nand the leading results [41, 44, 13, 16] on the challenging\\nImageNet dataset [36] all exploit “very deep” [41] models,\\nwith a depth of sixteen [41] to thirty [16]. Many other non-\\ntrivial visual recognition tasks [8, 12, 7, 32, 27] have also\\n1http://image-net.org/challenges/LSVRC/2015/ and\\nhttp://mscoco.org/dataset/#detections-challenge2015 .\\n0 1 2 3 4 5 60 1020\\niter. (1e4)training error (%)\\n  \\n0 1 2 3 4 5 601020\\niter. (1e4)test error (%)\\n  \\n56-layer\\n20-layer56-layer\\n20-layerFigure 1. Training error (left) and test error (right) on CIFAR-10\\nwith 20-layer and 56-layer “plain” networks. The deeper network\\nhas higher training error, and thus test error. Similar phenomena\\non ImageNet is presented in Fig. 4.\\ngreatly beneﬁted from very deep models.\\nDriven by the signiﬁcance of depth, a question arises: Is\\nlearning better networks as easy as stacking more layers?\\nAn obstacle to answering this question was the notorious\\nproblem of vanishing/exploding gradients [1, 9], which\\nhamper convergence from the beginning. This problem,\\nhowever, has been largely addressed by normalized initial-\\nization [23, 9, 37, 13] and intermediate normalization layers\\n[16], which enable networks with tens of layers to start con-\\nverging for stochastic gradient descent (SGD) with back-\\npropagation [22].\\nWhen deeper networks are able to start converging, a\\ndegradation problem has been exposed: with the network\\ndepth increasing, accuracy gets saturated (which might be\\nunsurprising) and then degrades rapidly. Unexpectedly,\\nsuch degradation is not caused by overﬁtting , and adding\\nmore layers to a suitably deep model leads to higher train-\\ning error , as reported in [11, 42] and thoroughly veriﬁed by\\nour experiments. Fig. 1 shows a typical example.\\nThe degradation (of training accuracy) indicates that not\\nall systems are similarly easy to optimize. Let us consider a\\nshallower architecture and its deeper counterpart that adds\\nmore layers onto it. There exists a solution by construction\\nto the deeper model: the added layers are identity mapping,\\nand the other layers are copied from the learned shallower', metadata={'source': 'resnet_arch.pdf', 'page': 0})"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b6b00d-286e-4c18-b564-893c7890f108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
